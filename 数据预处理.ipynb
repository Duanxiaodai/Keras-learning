{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 简介  \n",
    "在进行自然语言处理之前，需要对文本进行处理。   \n",
    "本文介绍keras提供的预处理包keras.preproceing下的text与序列处理模块sequence模块  \n",
    "\n",
    "2 text模块提供的方法  \n",
    "text_to_word_sequence(text,fileter) 可以简单理解此函数功能类str.split  \n",
    "one_hot(text,vocab_size) 基于hash函数(桶大小为vocab_size)，将一行文本转换向量表示  \n",
    "3 text.Tokenizer类  \n",
    "这个类用来对文本中的词进行统计计数，生成文档词典，以支持基于词典位序生成文本的向量表示。   \n",
    "init(num_words) 构造函数，传入词典的最大值  \n",
    "\n",
    "3.1 成员函数  \n",
    "fit_on_text(texts) 使用一系列文档来生成token词典，texts为list类，每个元素为一个文档。  \n",
    "texts_to_sequences(texts) 将多个文档转换为word下标的向量形式,shape为[len(texts)，len(text)]  \n",
    "texts_to_matrix(texts) 将多个文档转换为矩阵表示,shape为[len(texts),num_words]  \n",
    "3.2 成员变量  \n",
    "document_count 处理的文档数量  \n",
    "word_index 一个dict，保存所有word对应的编号id，从1开始  \n",
    "word_counts 一个dict，保存每个word在所有文档中出现的次数  \n",
    "word_docs 一个dict，保存每个word出现的文档的数量  \n",
    "index_docs 一个dict，保存word的id出现的文档的数量  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['some', 'thing', 'to', 'eat']\n",
      "[1, 9, 6, 1]\n",
      "[1, 9, 6, 5]\n",
      "OrderedDict([('some', 2), ('thing', 2), ('to', 2), ('eat', 1), ('drink', 1)])\n",
      "{'to': 3, 'some': 1, 'eat': 4, 'thing': 2, 'drink': 5}\n",
      "{'to': 2, 'some': 2, 'eat': 1, 'drink': 1, 'thing': 2}\n",
      "{1: 2, 2: 2, 3: 2, 4: 1, 5: 1}\n",
      "[[1, 2, 3, 4], [1, 2, 3, 5]]\n",
      "[[ 0.  1.  1.  1.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  1.  1.  0.  1.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import keras.preprocessing.text as T\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "text1='some thing to eat'\n",
    "text2='some thing to drink'\n",
    "texts=[text1,text2]\n",
    "\n",
    "print(T.text_to_word_sequence(text1) ) #['some', 'thing', 'to', 'eat']\n",
    "print(T.one_hot(text1,10))  #[7, 9, 3, 4]\n",
    "print (T.one_hot(text2,10))  #[7, 9, 3, 1]\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "print (tokenizer.word_counts) #[('some', 2), ('thing', 2), ('to', 2), ('eat', 1), ('drink', 1)]\n",
    "print (tokenizer.word_index) #{'some': 1, 'thing': 2,'to': 3 ','eat': 4, drink': 5}\n",
    "print (tokenizer.word_docs) #{'some': 2, 'thing': 2, 'to': 2, 'drink': 1,  'eat': 1}\n",
    "print (tokenizer.index_docs) #{1: 2, 2: 2, 3: 2, 4: 1, 5: 1}\n",
    "\n",
    "print (tokenizer.texts_to_sequences(texts)) #[[1, 2, 3, 4], [1, 2, 3, 5]]\n",
    "print (tokenizer.texts_to_matrix(texts)) #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 sequence模块  \n",
    "4.1 模块提供的方法  \n",
    "pad_sequences(sequences, maxlen, padding=’pre’, truncating=’pre’, value=0.) 将序列填充到maxlen长度，padding取值有pre|post，value指定用何值填充的值\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.preprocessing.sequence as S\n",
    "S.pad_sequences([[1,2,3]],10,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
