{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import LabelEncoder,Imputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1143, 75)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train set\n",
    "df_train = pd.read_csv('data/busara/train.csv')\n",
    "# test set\n",
    "df_test = pd.read_csv('data/busara/test.csv')\n",
    "#show the shape of the train dataframe\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def missing_values_table(df):\n",
    "    # Total missing values\n",
    "    mis_val = df.isnull().sum()\n",
    " \n",
    "    # Percentage of missing values\n",
    "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    " \n",
    "    # Make a table with the results\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    " \n",
    "    # Rename the columns\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(\n",
    "    columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    " \n",
    "    # Sort the table by percentage of missing descending\n",
    "    mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "    mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "    '% of Total Values', ascending=False).round(1)\n",
    " \n",
    "    # Print some summary information\n",
    "    print (\"The dataset has \" + str(df.shape[1]) + \" columns.\" \n",
    "    \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "    \" columns that have missing values.\")\n",
    " \n",
    "    # Return the dataframe with missing information\n",
    "    return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 71 columns.There are 19 columns that have missing values.\n",
      " 0 columns will be deleted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1143, 71)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the columns with > 50% missing\n",
    "missing_df = missing_values_table(df_train);\n",
    "missing_columns = list(missing_df[missing_df['% of Total Values'] > 50].index)\n",
    "print('','%d columns will be deleted.' % len(missing_columns))\n",
    "# Drop the columns with 50% missing data\n",
    "df_train = df_train.drop(list(missing_columns),axis=1)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a label (category) encoder object\n",
    "encoder = LabelEncoder()\n",
    "# fitting the encoder to the \"survey_date\" column\n",
    "encoder.fit(df_train['survey_date'])\n",
    "# Apply the fitted encoder to the \"survey_date\" to transform categories into integers\n",
    "encoded_train = encoder.transform(df_train['survey_date'])\n",
    "# encoded_test = encoder.transform(df_test['survey_date'])\n",
    "#assign the tranformed column back to the dataframe\n",
    "df_train['survey_date'] = encoded_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# split data into train and test sets\n",
    "X = df_train.drop([\"depressed\"], axis=1)\n",
    "# fill missing values with mean column values\n",
    "imputer = Imputer()\n",
    "transformed_X = imputer.fit_transform(X)\n",
    "y = df_train.depressed\n",
    "seed = 5\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X, y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(36, input_dim=70, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(36, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "765/765 [==============================] - 0s - loss: 4.6527 - acc: 0.6837     \n",
      "Epoch 2/100\n",
      "765/765 [==============================] - 0s - loss: 2.9802 - acc: 0.8105     \n",
      "Epoch 3/100\n",
      "765/765 [==============================] - 0s - loss: 3.0310 - acc: 0.8065     \n",
      "Epoch 4/100\n",
      "765/765 [==============================] - 0s - loss: 2.9770 - acc: 0.8144     \n",
      "Epoch 5/100\n",
      "765/765 [==============================] - 0s - loss: 2.9922 - acc: 0.8144     \n",
      "Epoch 6/100\n",
      "765/765 [==============================] - 0s - loss: 3.0113 - acc: 0.8131     \n",
      "Epoch 7/100\n",
      "765/765 [==============================] - 0s - loss: 2.9720 - acc: 0.8144     \n",
      "Epoch 8/100\n",
      "765/765 [==============================] - 0s - loss: 3.0131 - acc: 0.8118     \n",
      "Epoch 9/100\n",
      "765/765 [==============================] - 0s - loss: 2.9841 - acc: 0.8131     \n",
      "Epoch 10/100\n",
      "765/765 [==============================] - 0s - loss: 2.9919 - acc: 0.8144     \n",
      "Epoch 11/100\n",
      "765/765 [==============================] - 0s - loss: 2.9956 - acc: 0.8131     \n",
      "Epoch 12/100\n",
      "765/765 [==============================] - 0s - loss: 3.0604 - acc: 0.8092     \n",
      "Epoch 13/100\n",
      "765/765 [==============================] - 0s - loss: 2.9957 - acc: 0.8118     \n",
      "Epoch 14/100\n",
      "765/765 [==============================] - 0s - loss: 2.9761 - acc: 0.8118     \n",
      "Epoch 15/100\n",
      "765/765 [==============================] - 0s - loss: 2.8986 - acc: 0.8157     \n",
      "Epoch 16/100\n",
      "765/765 [==============================] - 0s - loss: 2.9725 - acc: 0.8078     \n",
      "Epoch 17/100\n",
      "765/765 [==============================] - 0s - loss: 2.9623 - acc: 0.8105     \n",
      "Epoch 18/100\n",
      "765/765 [==============================] - 0s - loss: 2.9341 - acc: 0.8118     \n",
      "Epoch 19/100\n",
      "765/765 [==============================] - 0s - loss: 2.9545 - acc: 0.8105     \n",
      "Epoch 20/100\n",
      "765/765 [==============================] - 0s - loss: 2.9485 - acc: 0.8105     \n",
      "Epoch 21/100\n",
      "765/765 [==============================] - 0s - loss: 2.9964 - acc: 0.8105     \n",
      "Epoch 22/100\n",
      "765/765 [==============================] - 0s - loss: 2.9462 - acc: 0.8131     \n",
      "Epoch 23/100\n",
      "765/765 [==============================] - 0s - loss: 2.9477 - acc: 0.8131     \n",
      "Epoch 24/100\n",
      "765/765 [==============================] - 0s - loss: 2.9446 - acc: 0.8118     \n",
      "Epoch 25/100\n",
      "765/765 [==============================] - 0s - loss: 2.9270 - acc: 0.8144     \n",
      "Epoch 26/100\n",
      "765/765 [==============================] - 0s - loss: 2.9373 - acc: 0.8078     \n",
      "Epoch 27/100\n",
      "765/765 [==============================] - 0s - loss: 2.9780 - acc: 0.8092     \n",
      "Epoch 28/100\n",
      "765/765 [==============================] - 0s - loss: 2.9902 - acc: 0.8118     \n",
      "Epoch 29/100\n",
      "765/765 [==============================] - 0s - loss: 2.9134 - acc: 0.8144     \n",
      "Epoch 30/100\n",
      "765/765 [==============================] - 0s - loss: 2.9026 - acc: 0.8144     \n",
      "Epoch 31/100\n",
      "765/765 [==============================] - 0s - loss: 2.9686 - acc: 0.8039     \n",
      "Epoch 32/100\n",
      "765/765 [==============================] - 0s - loss: 2.9542 - acc: 0.8105     \n",
      "Epoch 33/100\n",
      "765/765 [==============================] - 0s - loss: 2.9007 - acc: 0.8144     \n",
      "Epoch 34/100\n",
      "765/765 [==============================] - 0s - loss: 2.8894 - acc: 0.8105     \n",
      "Epoch 35/100\n",
      "765/765 [==============================] - 0s - loss: 2.8395 - acc: 0.8144     \n",
      "Epoch 36/100\n",
      "765/765 [==============================] - 0s - loss: 2.8710 - acc: 0.8118     \n",
      "Epoch 37/100\n",
      "765/765 [==============================] - 0s - loss: 2.7637 - acc: 0.8039     \n",
      "Epoch 38/100\n",
      "765/765 [==============================] - 0s - loss: 2.8330 - acc: 0.7948     \n",
      "Epoch 39/100\n",
      "765/765 [==============================] - 0s - loss: 2.5916 - acc: 0.8078     \n",
      "Epoch 40/100\n",
      "765/765 [==============================] - 0s - loss: 2.7174 - acc: 0.8013     \n",
      "Epoch 41/100\n",
      "765/765 [==============================] - 0s - loss: 2.5892 - acc: 0.7595     \n",
      "Epoch 42/100\n",
      "765/765 [==============================] - 0s - loss: 1.8847 - acc: 0.7242     \n",
      "Epoch 43/100\n",
      "765/765 [==============================] - 0s - loss: 1.2233 - acc: 0.7529     \n",
      "Epoch 44/100\n",
      "765/765 [==============================] - 0s - loss: 0.9592 - acc: 0.7359     \n",
      "Epoch 45/100\n",
      "765/765 [==============================] - 0s - loss: 0.7547 - acc: 0.7686     \n",
      "Epoch 46/100\n",
      "765/765 [==============================] - 0s - loss: 0.6927 - acc: 0.7974     \n",
      "Epoch 47/100\n",
      "765/765 [==============================] - 0s - loss: 0.6037 - acc: 0.8039     \n",
      "Epoch 48/100\n",
      "765/765 [==============================] - 0s - loss: 0.6127 - acc: 0.7908     \n",
      "Epoch 49/100\n",
      "765/765 [==============================] - 0s - loss: 0.5858 - acc: 0.8039     \n",
      "Epoch 50/100\n",
      "765/765 [==============================] - 0s - loss: 0.5293 - acc: 0.8105     \n",
      "Epoch 51/100\n",
      "765/765 [==============================] - 0s - loss: 0.5272 - acc: 0.8118     \n",
      "Epoch 52/100\n",
      "765/765 [==============================] - 0s - loss: 0.5528 - acc: 0.8065     \n",
      "Epoch 53/100\n",
      "765/765 [==============================] - 0s - loss: 0.5400 - acc: 0.8157     \n",
      "Epoch 54/100\n",
      "765/765 [==============================] - 0s - loss: 0.5410 - acc: 0.8092     \n",
      "Epoch 55/100\n",
      "765/765 [==============================] - 0s - loss: 0.5232 - acc: 0.8118     \n",
      "Epoch 56/100\n",
      "765/765 [==============================] - 0s - loss: 0.5483 - acc: 0.8118     \n",
      "Epoch 57/100\n",
      "765/765 [==============================] - 0s - loss: 0.5400 - acc: 0.8118     \n",
      "Epoch 58/100\n",
      "765/765 [==============================] - 0s - loss: 0.4860 - acc: 0.8144     \n",
      "Epoch 59/100\n",
      "765/765 [==============================] - 0s - loss: 0.4996 - acc: 0.8157     \n",
      "Epoch 60/100\n",
      "765/765 [==============================] - 0s - loss: 0.5065 - acc: 0.8170     \n",
      "Epoch 61/100\n",
      "765/765 [==============================] - 0s - loss: 0.5012 - acc: 0.8092     \n",
      "Epoch 62/100\n",
      "765/765 [==============================] - 0s - loss: 0.5117 - acc: 0.8144     \n",
      "Epoch 63/100\n",
      "765/765 [==============================] - 0s - loss: 0.5223 - acc: 0.8118     \n",
      "Epoch 64/100\n",
      "765/765 [==============================] - 0s - loss: 0.5200 - acc: 0.8131     \n",
      "Epoch 65/100\n",
      "765/765 [==============================] - 0s - loss: 0.4950 - acc: 0.8157     \n",
      "Epoch 66/100\n",
      "765/765 [==============================] - 0s - loss: 0.5090 - acc: 0.8105     \n",
      "Epoch 67/100\n",
      "765/765 [==============================] - 0s - loss: 0.5133 - acc: 0.8144     \n",
      "Epoch 68/100\n",
      "765/765 [==============================] - 0s - loss: 0.4746 - acc: 0.8105     \n",
      "Epoch 69/100\n",
      "765/765 [==============================] - 0s - loss: 0.4971 - acc: 0.8144     \n",
      "Epoch 70/100\n",
      "765/765 [==============================] - 0s - loss: 0.4946 - acc: 0.8144     \n",
      "Epoch 71/100\n",
      "765/765 [==============================] - 0s - loss: 0.4990 - acc: 0.8157     \n",
      "Epoch 72/100\n",
      "765/765 [==============================] - 0s - loss: 0.5109 - acc: 0.8092     \n",
      "Epoch 73/100\n",
      "765/765 [==============================] - 0s - loss: 0.4834 - acc: 0.8105     \n",
      "Epoch 74/100\n",
      "765/765 [==============================] - 0s - loss: 0.4743 - acc: 0.8144     \n",
      "Epoch 75/100\n",
      "765/765 [==============================] - 0s - loss: 0.4821 - acc: 0.8144     \n",
      "Epoch 76/100\n",
      "765/765 [==============================] - 0s - loss: 0.4760 - acc: 0.8144     \n",
      "Epoch 77/100\n",
      "765/765 [==============================] - 0s - loss: 0.5009 - acc: 0.8144     \n",
      "Epoch 78/100\n",
      "765/765 [==============================] - 0s - loss: 0.4840 - acc: 0.8131     \n",
      "Epoch 79/100\n",
      "765/765 [==============================] - 0s - loss: 0.4925 - acc: 0.8144     \n",
      "Epoch 80/100\n",
      "765/765 [==============================] - 0s - loss: 0.4848 - acc: 0.8144     \n",
      "Epoch 81/100\n",
      "765/765 [==============================] - 0s - loss: 0.4913 - acc: 0.8131     \n",
      "Epoch 82/100\n",
      "765/765 [==============================] - 0s - loss: 0.4856 - acc: 0.8131     \n",
      "Epoch 83/100\n",
      "765/765 [==============================] - 0s - loss: 0.4772 - acc: 0.8157     \n",
      "Epoch 84/100\n",
      "765/765 [==============================] - 0s - loss: 0.4827 - acc: 0.8118     \n",
      "Epoch 85/100\n",
      "765/765 [==============================] - 0s - loss: 0.4924 - acc: 0.8118     \n",
      "Epoch 86/100\n",
      "765/765 [==============================] - 0s - loss: 0.4717 - acc: 0.8118     \n",
      "Epoch 87/100\n",
      "765/765 [==============================] - 0s - loss: 0.4765 - acc: 0.8131     \n",
      "Epoch 88/100\n",
      "765/765 [==============================] - 0s - loss: 0.4707 - acc: 0.8157     \n",
      "Epoch 89/100\n",
      "765/765 [==============================] - 0s - loss: 0.4685 - acc: 0.8170     \n",
      "Epoch 90/100\n",
      "765/765 [==============================] - 0s - loss: 0.4794 - acc: 0.8157     \n",
      "Epoch 91/100\n",
      "765/765 [==============================] - 0s - loss: 0.4700 - acc: 0.8144     \n",
      "Epoch 92/100\n",
      "765/765 [==============================] - 0s - loss: 0.4988 - acc: 0.8131     \n",
      "Epoch 93/100\n",
      "765/765 [==============================] - 0s - loss: 0.4655 - acc: 0.8157     \n",
      "Epoch 94/100\n",
      "765/765 [==============================] - 0s - loss: 0.4604 - acc: 0.8170     \n",
      "Epoch 95/100\n",
      "765/765 [==============================] - 0s - loss: 0.4677 - acc: 0.8183     \n",
      "Epoch 96/100\n",
      "765/765 [==============================] - 0s - loss: 0.4807 - acc: 0.8131     \n",
      "Epoch 97/100\n",
      "765/765 [==============================] - 0s - loss: 0.4591 - acc: 0.8209     \n",
      "Epoch 98/100\n",
      "765/765 [==============================] - 0s - loss: 0.4725 - acc: 0.8183     \n",
      "Epoch 99/100\n",
      "765/765 [==============================] - 0s - loss: 0.4648 - acc: 0.8170     \n",
      "Epoch 100/100\n",
      "765/765 [==============================] - 0s - loss: 0.4560 - acc: 0.8157     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x237445e3c88>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/378 [=>............................] - ETA: 2sacc: 86.24%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
